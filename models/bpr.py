# -*- coding: utf-8 -*-
"""BPR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fHAfX27ZZndZqHVHELwsP_rM8bQ4BK5l
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

!pip install lightfm

from lightfm import LightFM
from lightfm.datasets import fetch_movielens
from lightfm.evaluation import precision_at_k
from lightfm.data import Dataset
from lightfm.cross_validation import random_train_test_split

data = pd.read_csv("Sampled_UserBehavior_cleaned.csv")

df=data.iloc[:,1:5]
# We give each kind of behavior a value that represents its importance.
value_mapping = {"pv":1,"fav":2,"cart":3,"buy":4}
# Option to drop the duplicates rows
# df_no_duplicates = df.drop_duplicates()

df["Behavior"]=df["Behavior"].map(value_mapping)
result = df.groupby(['User_ID', 'Categorical_ID']).agg({'Behavior': 'sum'}).reset_index()

from scipy.sparse import coo_matrix

userID = result["User_ID"].values
itemID = result["Categorical_ID"].values
interactions = result["Behavior"]
unique_user_ids = np.unique(userID)
unique_item_ids = np.unique(itemID)

user_id_to_index = {user_id: index for index, user_id in enumerate(unique_user_ids)}
item_id_to_index = {item_id: index for index, item_id in enumerate(unique_item_ids)}

user_indices = [user_id_to_index[user_id] for user_id in userID]
item_indices = [item_id_to_index[item_id] for item_id in itemID]

interactions_matrix = coo_matrix((interactions, (user_indices, item_indices)), shape=(len(unique_user_ids), len(unique_item_ids)))
train, test = random_train_test_split(interactions_matrix, random_state = 123123)

model = LightFM(loss="bpr")
model.fit(train, epochs=30, num_threads=2)

from lightfm.evaluation import precision_at_k, auc_score
auc = auc_score(model, test).mean()
precision5 = precision_at_k(model, test, k=5).mean()
precision20 = precision_at_k(model, test, k=20).mean()
[auc, precision5, precision20]

pred = model.predict_rank(test)
t = test.toarray()


from sklearn.metrics import roc_curve, auc
test_user =822
# get the prediction scores
predictions = model.predict(test_user, np.arange(t.shape[1]))
# binarize the test interactions for roc_curve function
binarized_test_interactions = np.int32(t[test_user,:] > 0)

# calculate FPR, TPR, and thresholds for the test user
fpr, tpr, thresholds = roc_curve(binarized_test_interactions, predictions)

# compute Area Under the Curve (AUC)
roc_auc = auc(fpr, tpr)

# Now, let's plot the curve
plt.figure()
lw = 2  # line width
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

# Draw the ROC plot for all individual users
from sklearn.metrics import roc_curve, auc
t = train.toarray()
for i in range(train.shape[0]):
    test_user = i
    predictions = model.predict(test_user, np.arange(train.shape[1]))
    # binarize the test interactions for roc_curve function
    binarized_test_interactions = np.int32(t[test_user,:] > 0)

    # calculate FPR, TPR, and thresholds for the test user
    fpr, tpr, thresholds = roc_curve(binarized_test_interactions, predictions)
    # compute Area Under the Curve (AUC)
    roc_auc = auc(fpr, tpr)

    # Now, let's plot the curve
    lw = 2  # line width
    plt.plot(fpr, tpr,alpha=0.2, color='black', linewidth=0.1)#, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()